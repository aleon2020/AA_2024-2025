{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cap√≠tulo 14: Clasificaci√≥n de Im√°genes con Redes Neuronales Convolucionales Profundas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# √çndice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Componentes b√°sicos de las CNN](#componentes-b√°sicos-de-las-cnn)\n",
    "- [Comprensi√≥n de las CNN y las jerarqu√≠as de funciones](#comprensi√≥n-de-las-cnn-y-las-jerarqu√≠as-de-funciones)\n",
    "- [Realizaci√≥n de Convoluciones Discretas](#realizaci√≥n-de-convoluciones-discretas)\n",
    "- [Convoluciones Discretas en 1 Dimensi√≥n](#convoluciones-discretas-en-1-dimensi√≥n)\n",
    "- [Relleno de entradas para controlar el tama√±o de los mapas de caracter√≠sticas de salida](#relleno-de-entradas-para-controlar-el-tama√±o-de-los-mapas-de-caracter√≠sticas-de-salida)\n",
    "- [Determinaci√≥n del tama√±o de salida de la convoluci√≥n](#determinaci√≥n-del-tama√±o-de-salida-de-la-convoluci√≥n)\n",
    "- [Convoluciones Discretas en 2 Dimensiones](#convoluciones-discretas-en-2-dimensiones)\n",
    "- [Submuestreo o agrupaci√≥n de capas](#submuestreo-o-agrupaci√≥n-de-capas)\n",
    "- [Trabajo con m√∫ltiples canales de entrada o de color](#trabajo-con-m√∫ltiples-canales-de-entrada-o-de-color)\n",
    "- [Funciones de activaci√≥n](#funciones-de-activaci√≥n)\n",
    "- [Funciones de p√©rdida para clasificaci√≥n](#funciones-de-p√©rdida-para-clasificaci√≥n)\n",
    "- [Implementaci√≥n de una CNN profunda usando PyTorch](#implementaci√≥n-de-una-cnn-profunda-usando-pytorch)\n",
    "- [Convertir Jupyter Notebook a Fichero Python](#convertir-jupyter-notebook-a-fichero-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Componentes b√°sicos de las CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las redes neuronales convolucionales (CNN) son una familia de modelos que fueron originalmente inspirados en c√≥mo funciona la corteza visual del cerebro humano cuando reconocemos objetos.\n",
    "\n",
    "El desarrollo de las CNN se remonta a la d√©cada de 1990, cuando Yann LeCun y sus colegas propusieron una arquitectura NN novedosa para clasificar d√≠gitos escritos a mano a partir de im√°genes.\n",
    "\n",
    "Debido al excelente desempe√±o de las CNN para tareas de clasificaci√≥n de im√°genes, este tipo particular de NN feedforward gan√≥ mucha atenci√≥n y condujo a enormes mejoras en el aprendizaje autom√°tico para visi√≥n computacional.\n",
    "\n",
    "Varios a√±os despu√©s, en 2019, Yann LeCun recibi√≥ el premio Turing (el premio m√°s prestigioso en inform√°tica) por sus contribuciones al campo de inteligencia artificial (IA), junto con otros dos investigadores, Yoshua Bengio y Geoffrey Hinton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprensi√≥n de las CNN y las jerarqu√≠as de funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La extracci√≥n exitosa de caracter√≠sticas relevantes es clave para el rendimiento de cualquier algoritmo de aprendizaje autom√°tico y el aprendizaje autom√°tico tradicional. Los modelos se basan en caracter√≠sticas de entrada que pueden provenir de un experto en el dominio o se basan en la selecci√≥n o extracci√≥n de caracter√≠sticas computacionales t√©cnicas.\n",
    "\n",
    "Ciertos tipos de NN, como las CNN, pueden aprender autom√°ticamente caracter√≠sticas de datos sin procesar que son m√°s √∫tiles para una tarea particular. Por esta raz√≥n, es com√∫n considerar las capas CNN como caracter√≠sticas para extraer:\n",
    "\n",
    "‚Ä¢ Las primeras capas (las que est√°n inmediatamente despu√©s de la capa de entrada) extraen caracter√≠sticas de bajo nivel a partir de datos sin procesar, y las capas posteriores (a menudo capas completamente conectadas, como en un perceptr√≥n multicapa (MLP) utiliza estas caracter√≠sticas para predecir un objetivo continuo (etiqueta de valor o clase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; justify-content: center;\">\n",
       "    <img src=\"./figures/14_01.png\" format=\"png\">\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, HTML\n",
    "display(HTML(\"\"\"\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"./figures/14_01.png\" format=\"png\">\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ciertos tipos de NN multicapa y, en particular, las CNN profundas, construyen la llamada jerarqu√≠a de caracter√≠sticas combinando las caracter√≠sticas de bajo nivel en forma de capas para formar caracter√≠sticas de alto nivel.\n",
    "\n",
    "Por ejemplo, si estamos tratando con im√°genes, entonces el nivel bajo de caracter√≠sticas, como bordes y manchas, se extraen de capas anteriores, que se combinan para formar entidades de alto nivel.\n",
    "\n",
    "Estas caracter√≠sticas de alto nivel pueden formar formas m√°s complejas, como los contornos generales de objetos como edificios, gatos o perros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; justify-content: center;\">\n",
       "    <img src=\"./figures/14_02.png\" format=\"png\">\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, HTML\n",
    "display(HTML(\"\"\"\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"./figures/14_02.png\" format=\"png\">\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una CNN calcula mapas de caracter√≠sticas a partir de una imagen de entrada, donde cada elemento proviene de un parche local de p√≠xeles en la imagen de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; justify-content: center;\">\n",
       "    <img src=\"./figures/14_03.png\" format=\"png\">\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, HTML\n",
    "display(HTML(\"\"\"\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"./figures/14_03.png\" format=\"png\">\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las CNN funcionan muy bien en tareas relacionadas con im√°genes y eso se debe en gran medida a dos ideas importantes:\n",
    "\n",
    "‚Ä¢ Conectividad escasa: Un √∫nico elemento en el mapa de caracter√≠sticas est√° conectado solo a una peque√±a porci√≥n de p√≠xeles (esto es muy diferente de conectarse a toda la imagen de entrada, como en el caso de los MLP).\n",
    "\n",
    "‚Ä¢ Compartir par√°metros: Se utilizan los mismos pesos para diferentes parches de la imagen de entrada.\n",
    "\n",
    "Como consecuencia directa de estas dos ideas, la sustituci√≥n de un sistema convencional, MLP completamente conectado con una capa de convoluci√≥n disminuye sustancialmente la cantidad de pesos (par√°metros) en la red, por lo que veremos una mejora en la capacidad de capturar caracter√≠sticas relevantes.\n",
    "\n",
    "En el contexto de los datos de im√°genes, tiene sentido suponer que las personas cercanas a los p√≠xeles suelen ser m√°s relevantes entre s√≠ que los p√≠xeles que est√°n m√°s alejados.\n",
    "\n",
    "Normalmente, las CNN se componen de varias capas de submuestreo convolucionales que van seguidas de una o m√°s capas conectadas al final. Las capas completamente conectadas son esencialmente un MLP.\n",
    "\n",
    "Las capas de submuestreo, com√∫nmente conocidas como capas de agrupaci√≥n, no tienen par√°metros que se puedan aprender.\n",
    "No hay pesos ni unidades de polarizaci√≥n en las capas de agrupaci√≥n. Sin embargo, tanto la capa convolucional como la completamente conectada tienen pesos y sesgos que se optimizan durante el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizaci√≥n de Convoluciones Discretas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entender c√≥mo funcionan las operaciones de convoluci√≥n, comencemos con un convoluci√≥n en una dimensi√≥n, que a veces se utiliza para trabajar con ciertos tipos de datos de secuencia, como texto.\n",
    "\n",
    "Una convoluci√≥n discreta (o simplemente convoluci√≥n) es un elemento fundamental de operaci√≥n en una CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convoluciones Discretas en 1 Dimensi√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una convoluci√≥n discreta para dos vectores, x y w, se denota por y = x * w, en el cual el vector x es nuestra entrada (a veces llamada se√±al) y w se llama filtro o n√∫cleo.\n",
    "\n",
    "Una convoluci√≥n discreta se define matem√°ticamente de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; justify-content: center;\">\n",
       "    <img src=\"./figures/14_04.png\" format=\"png\">\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, HTML\n",
    "display(HTML(\"\"\"\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"./figures/14_04.png\" format=\"png\">\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El hecho de que la suma pase por √≠ndices de ‚Äì‚àû a +‚àû parece extra√±o, principalmente porque en las aplicaciones de aprendizaje autom√°tico, siempre tratamos con vectores de caracter√≠sticas finitas.\n",
    "\n",
    "Por ejemplo, si x tiene 10 caracter√≠sticas con √≠ndices 0, 1, 2, ..., 8, 9, entonces los √≠ndices ‚Äì‚àû:-1 y 10:+‚àû est√°n fuera de los l√≠mites para x.\n",
    "\n",
    "Por lo tanto, para calcular correctamente la suma que se muestra en el punto anterior f√≥rmula, se supone que x y w est√°n llenos de ceros.\n",
    "\n",
    "Esto dar√° como resultado un vector de salida, y, que tambi√©n tiene tama√±o infinito, con muchos ceros tambi√©n.\n",
    "\n",
    "Dado que esto no es √∫til en situaciones pr√°cticas, x se rellena s√≥lo con un valor finito n√∫mero de ceros.\n",
    "\n",
    "Este proceso se llama relleno con ceros o simplemente relleno. Aqu√≠, el n√∫mero de ceros rellenados en cada lado se indica con p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; justify-content: center;\">\n",
       "    <img src=\"./figures/14_05.png\" format=\"png\">\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, HTML\n",
    "display(HTML(\"\"\"\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"./figures/14_05.png\" format=\"png\">\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que la entrada original, x, y el filtro, w, tienen n y m elementos, respectivamente, donde m ‚â§ n.\n",
    "\n",
    "El vector acolchado, xp, tiene tama√±o n + 2p. La f√≥rmula pr√°ctica para calcular una convoluci√≥n discreta cambiar√° a lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; justify-content: center;\">\n",
       "    <img src=\"./figures/14_06.png\" format=\"png\">\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, HTML\n",
    "display(HTML(\"\"\"\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"./figures/14_06.png\" format=\"png\">\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de que el tama√±o del relleno es cero (p=0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; justify-content: center;\">\n",
       "    <img src=\"./figures/14_07.png\" format=\"png\">\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, HTML\n",
    "display(HTML(\"\"\"\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"./figures/14_07.png\" format=\"png\">\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa que el filtro girado, wr, es desplazado en dos celdas cada vez que cambiamos.\n",
    "\n",
    "Este cambio es otro hiperpar√°metro de una circunvoluci√≥n, la zancada, s.\n",
    "\n",
    "En este ejemplo, la zancada es dos, s = 2.\n",
    "\n",
    "Tenga en cuenta que la zancada debe ser n√∫mero positivo menor que el tama√±o del vector de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; justify-content: center;\">\n",
       "    <img src=\"./figures/14_08.png\" format=\"png\">\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, HTML\n",
    "display(HTML(\"\"\"\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"./figures/14_08.png\" format=\"png\">\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relleno de entradas para controlar el tama√±o de los mapas de caracter√≠sticas de salida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay tres modos de relleno que se utilizan com√∫nmente en pr√°ctica: plena, igual y v√°lida.\n",
    "\n",
    "‚Ä¢ En modo completo, el par√°metro de relleno, p, se establece en p = m ‚Äì 1. Relleno completo aumenta las dimensiones de la salida; por lo tanto, rara vez se usa en arquitecturas CNN.\n",
    "\n",
    "‚Ä¢ Generalmente se utiliza el mismo modo de relleno para garantizar que el vector de salida tiene el mismo tama√±o que el vector de entrada, x. En este caso, el par√°metro de relleno, p, se calcula seg√∫n el tama√±o del filtro, junto con el requisito de que el tama√±o de entrada y el tama√±o de salida sean los mismos.\n",
    "\n",
    "‚Ä¢ Finalmente, calcular una convoluci√≥n en modo v√°lido se refiere al caso donde p = 0 (sin relleno).\n",
    "\n",
    "El modo de relleno m√°s utilizado en las CNN es el mismo relleno.\n",
    "\n",
    "Una de sus ventajas sobre los otros modos de relleno es la misma. El relleno preserva el tama√±o del vector, lo que facilita el dise√±o y una arquitectura de red m√°s conveniente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; justify-content: center;\">\n",
       "    <img src=\"./figures/14_09.png\" format=\"png\">\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, HTML\n",
    "display(HTML(\"\"\"\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"./figures/14_09.png\" format=\"png\">\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determinaci√≥n del tama√±o de salida de la convoluci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que el vector de entrada es de tama√±o n y el filtro es de talla m.\n",
    "\n",
    "Entonces, el tama√±o de la salida resultante de y = x * w, con relleno p y zancada s, se determinar√≠an de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; justify-content: center;\">\n",
       "    <img src=\"./figures/14_10.png\" format=\"png\">\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, HTML\n",
    "display(HTML(\"\"\"\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"./figures/14_10.png\" format=\"png\">\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; justify-content: center;\">\n",
       "    <img src=\"./figures/14_11.png\" format=\"png\">\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, HTML\n",
    "display(HTML(\"\"\"\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"./figures/14_11.png\" format=\"png\">\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convoluciones Discretas en 2 Dimensiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando trabajamos con entradas 2D, como una matriz, ùëøùëõ1√óùëõ2, y la matriz de filtro, ùëæùëö1√óùëö2, donde ùëö1 ‚â§ ùëõ1 y ùëö2 ‚â§ ùëõ2, entonces la matriz ùíÄ=ùëø*ùëæ es el resultado de una convoluci√≥n 2D entre ùëø y ùëæ. Esto es definido matem√°ticamente de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; justify-content: center;\">\n",
       "    <img src=\"./figures/14_12.png\" format=\"png\">\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, HTML\n",
    "display(HTML(\"\"\"\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"./figures/14_12.png\" format=\"png\">\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; justify-content: center;\">\n",
       "    <img src=\"./figures/14_13.png\" format=\"png\">\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, HTML\n",
    "display(HTML(\"\"\"\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"./figures/14_13.png\" format=\"png\">\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; justify-content: center;\">\n",
       "    <img src=\"./figures/14_14.png\" format=\"png\">\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, HTML\n",
    "display(HTML(\"\"\"\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"./figures/14_14.png\" format=\"png\">\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submuestreo o agrupaci√≥n de capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El submuestreo se aplica normalmente en dos formas de agrupaci√≥n operaciones en CNN: Agrupaci√≥n m√°xima y agrupaci√≥n media (tambi√©n conocida como agrupaci√≥n promedio).\n",
    "\n",
    "La capa de agrupaci√≥n generalmente se denota por ùëÉùëõ1√óùëõ2. Aqu√≠ el sub√≠ndice determina el tama√±o del vecindario (el n√∫mero de p√≠xeles vecinos en cada dimensi√≥n) donde la operaci√≥n m√°xima o media es realizada. A este tipo de vecindario nos referimos como tama√±o de la agrupaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; justify-content: center;\">\n",
       "    <img src=\"./figures/14_15.png\" format=\"png\">\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, HTML\n",
    "display(HTML(\"\"\"\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"./figures/14_15.png\" format=\"png\">\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La agrupaci√≥n (max-pooling) introduce una invariancia local. Esto significa que peque√±os cambios en EL vecindario local no cambia el resultado de la agrupaci√≥n m√°xima.\n",
    "\n",
    "Por lo tanto, ayuda a generar caracter√≠sticas que sean m√°s resistentes al ruido en la entrada de datos.\n",
    "\n",
    "En el siguiente ejemplo se muestra que la agrupaci√≥n m√°xima de dos diferentes matrices de entrada, X1 y X2, dan como resultado la misma salida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; justify-content: center;\">\n",
       "    <img src=\"./figures/14_16.png\" format=\"png\">\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, HTML\n",
    "display(HTML(\"\"\"\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"./figures/14_16.png\" format=\"png\">\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La agrupaci√≥n disminuye el tama√±o de las caracter√≠sticas, lo que resulta en una mayor capacidad de eficiencia computacional. Adem√°s, reducir el n√∫mero de funciones puede reducir tambi√©n el grado de sobreajuste.\n",
    "\n",
    "Tradicionalmente, se supone que la agrupaci√≥n no se superpone.\n",
    "\n",
    "La agrupaci√≥n generalmente se realiza en vecindarios que no se superponen, lo que se puede hacer estableciendo el par√°metro de zancada igual al tama√±o de la agrupaci√≥n. Por ejemplo, una capa de agrupaci√≥n que no se superpone, ùëÉùëõ1√óùëõ2, requiere un paso par√°metro s = (n1, n2).\n",
    "\n",
    "Si bien la agrupaci√≥n sigue siendo una parte esencial de muchas arquitecturas de CNN, tambi√©n se han desarrollado varias arquitecturas CNN sin utilizar capas de agrupaci√≥n.\n",
    "\n",
    "En lugar de utilizar capas de agrupaci√≥n para reducir el tama√±o de la entidad, los investigadores usan capas convolucionales con un paso de 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabajo con m√∫ltiples canales de entrada o de color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una entrada a una capa convolucional puede contener una o m√°s matrices 2D o matrices con dimensiones N1√óN2 (por ejemplo, la altura de la imagen y ancho en p√≠xeles).\n",
    "\n",
    "Estas matrices N1√óN2 se llaman canales.\n",
    "\n",
    "Las implementaciones convencionales de capas convolucionales esperan una representaci√≥n tensorial de rango 3 como entrada, por ejemplo, una representaci√≥n tridimensional. matriz, ùëøùëÅ1√óùëÅ2√óùê∂ùëñn, donde Cin es el n√∫mero de canales de entrada.\n",
    "\n",
    "Por ejemplo, consideremos im√°genes como entrada a la primera capa de una CNN. Si la imagen est√° coloreada y utiliza el modo de color RGB, entonces Cin = 3 (para los canales de color rojo, verde y azul en RGB).\n",
    "\n",
    "Sin embargo, si la imagen est√° en escala de grises, entonces tenemos Cin=1, porque solo hay un canal con los valores de intensidad de p√≠xeles en escala de grises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; justify-content: center;\">\n",
       "    <img src=\"./figures/14_17.png\" format=\"png\">\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, HTML\n",
    "display(HTML(\"\"\"\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"./figures/14_17.png\" format=\"png\">\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de activaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tienen diferentes funciones de activaci√≥n, como ReLU, sigmoide y tanh.\n",
    "\n",
    "Algunas de estas funciones de activaci√≥n, como ReLU, se utilizan principalmente en las capas intermedias (ocultas) de una NN para agregar no linealidades a nuestro modelo.\n",
    "\n",
    "Otros, como sigmoide (para binario) y softmax (para multiclase), se agregan en la √∫ltima capa (salida), lo que da como resultado probabilidades de membres√≠a de clase como salida del modelo.\n",
    "\n",
    "Si las activaciones sigmoidea o softmax no est√°n incluidas en el capa de salida, entonces el modelo calcular√° los logits en lugar de las probabilidades de pertenencia a una clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de p√©rdida para clasificaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centrarse en los problemas de clasificaci√≥n, dependiendo del tipo de problema (binario versus multiclase) y el tipo de salida (logits versus probabilidades), debemos elegir la funci√≥n de p√©rdida apropiada para entrenar nuestro modelo.\n",
    "\n",
    "‚Ä¢ La entrop√≠a cruzada binaria es la funci√≥n de p√©rdida para una clasificaci√≥n binaria (con una sola unidad de salida).\n",
    "\n",
    "‚Ä¢ La entrop√≠a cruzada categ√≥rica es la funci√≥n de p√©rdida para clasificaci√≥n multiclase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; justify-content: center;\">\n",
       "    <img src=\"./figures/14_18.png\" format=\"png\">\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, HTML\n",
    "display(HTML(\"\"\"\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"./figures/14_18.png\" format=\"png\">\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Binary Cross-entropy\n",
    "logits = torch.tensor([0.8])\n",
    "probas = torch.sigmoid(logits)\n",
    "target = torch.tensor([1.0])\n",
    "bce_loss_fn = nn.BCELoss()\n",
    "bce_logits_loss_fn = nn.BCEWithLogitsLoss()\n",
    "print(f'BCE (w Probas): {bce_loss_fn(probas, target):.4f}')\n",
    "print(f'BCE (w Logits): {bce_logits_loss_fn(logits, target):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Categorical Cross-entropy\n",
    "logits = torch.tensor([[1.5, 0.8, 2.1]])\n",
    "probas = torch.softmax(logits, dim=1)\n",
    "target = torch.tensor([2])\n",
    "cce_loss_fn = nn.NLLLoss()\n",
    "cce_logits_loss_fn = nn.CrossEntropyLoss()\n",
    "print(f'CCE (w Logits): {cce_logits_loss_fn(logits, target):.4f}')\n",
    "print(f'CCE (w Probas): {cce_loss_fn(torch.log(probas), target):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementaci√≥n de una CNN profunda usando PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; justify-content: center;\">\n",
       "    <img src=\"./figures/14_19.png\" format=\"png\">\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, HTML\n",
    "display(HTML(\"\"\"\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"./figures/14_19.png\" format=\"png\">\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "image_path = './'\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "mnist_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root=image_path, train=True,\n",
    "    transform=transform, download=True\n",
    ")\n",
    "from torch.utils.data import Subset\n",
    "mnist_valid_dataset = Subset(mnist_dataset, \n",
    "                             torch.arange(10000))\n",
    "mnist_train_dataset = Subset(mnist_dataset, \n",
    "                             torch.arange(\n",
    "                                 10000, len(mnist_dataset)\n",
    "                            ))\n",
    "mnist_test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root=image_path, train=False,\n",
    "    transform=transform, download=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "torch.manual_seed(1)\n",
    "train_dl = DataLoader(mnist_train_dataset,\n",
    "                      batch_size,\n",
    "                      shuffle=True)\n",
    "\n",
    "valid_dl = DataLoader(mnist_valid_dataset,\n",
    "                      batch_size,\n",
    "                      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "model.add_module(\n",
    "    'conv1',\n",
    "    nn.Conv2d(\n",
    "        in_channels=1, out_channels=32,\n",
    "        kernel_size=5, padding=2\n",
    "    )\n",
    ")\n",
    "model.add_module('relu1', nn.ReLU())\n",
    "model.add_module('pool1', nn.MaxPool2d(kernel_size=2))\n",
    "model.add_module(\n",
    "    'conv2',\n",
    "    nn.Conv2d(\n",
    "        in_channels=32, out_channels=64,\n",
    "        kernel_size=5, padding=2\n",
    "    )\n",
    ")\n",
    "model.add_module('relu2', nn.ReLU())\n",
    "model.add_module('pool2', nn.MaxPool2d(kernel_size=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al proporcionar la forma de entrada como una tupla (4, 1, 28, 28) (4 im√°genes dentro del lote, 1 canal y tama√±o de imagen 28√ó28), especificado en este ejemplo, calculamos la salida tenga una forma (4, 64, 7, 7), indicando mapas de caracter√≠sticas con 64 canales y un tama√±o espacial de 7√ó7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones((4, 1, 28, 28))\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_module('flatten', nn.Flatten())\n",
    "x = torch.ones((4, 1, 28, 28))\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_module('fc1', nn.Linear(3136, 1024))\n",
    "model.add_module('relu3', nn.ReLU())\n",
    "model.add_module('dropout', nn.Dropout(p=0.5))\n",
    "model.add_module('fc2', nn.Linear(1024, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, num_epochs, train_dl, valid_dl):\n",
    "    loss_hist_train = [0] * num_epochs\n",
    "    accuracy_hist_train = [0] * num_epochs\n",
    "    loss_hist_valid = [0] * num_epochs\n",
    "    accuracy_hist_valid = [0] * num_epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for x_batch, y_batch in train_dl:\n",
    "            x_batch = x_batch.cpu()\n",
    "            y_batch = y_batch.cpu()\n",
    "            pred = model(x_batch)\n",
    "            loss = loss_fn(pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss_hist_train[epoch] += loss.item()*y_batch.size(0)\n",
    "            is_correct = (\n",
    "                torch.argmax(pred, dim=1) == y_batch\n",
    "            ).float()\n",
    "            accuracy_hist_train[epoch] += is_correct.sum()\n",
    "        loss_hist_train[epoch] /= len(train_dl.dataset)\n",
    "        accuracy_hist_train[epoch] /= len(train_dl.dataset)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in valid_dl:\n",
    "                x_batch = x_batch.cpu()\n",
    "                y_batch = y_batch.cpu()\n",
    "                pred = model(x_batch)\n",
    "                loss = loss_fn(pred, y_batch)\n",
    "                loss_hist_valid[epoch] += \\\n",
    "                    loss.item()*y_batch.size(0)\n",
    "                is_correct = (\n",
    "                    torch.argmax(pred, dim=1) == y_batch\n",
    "                ).float()\n",
    "                accuracy_hist_valid[epoch] += is_correct.sum()\n",
    "        loss_hist_valid[epoch] /= len(valid_dl.dataset)\n",
    "        accuracy_hist_valid[epoch] /= len(valid_dl.dataset)\n",
    "        \n",
    "        print(f'Epoch {epoch+1} accuracy: '\n",
    "              f'{accuracy_hist_train[epoch]:.4f} val_accuracy: '\n",
    "              f'{accuracy_hist_valid[epoch]:.4f}')\n",
    "        \n",
    "    return loss_hist_train, loss_hist_valid, \\\n",
    "        accuracy_hist_train, accuracy_hist_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "num_epochs = 20\n",
    "hist = train(model, num_epochs, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x_arr = np.arange(len(hist[0])) + 1\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(x_arr, hist[0], '--o', label='Train loss')\n",
    "ax.plot(x_arr, hist[1], '--c', label='Validation loss')\n",
    "ax.legend(fontsize=15)\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(x_arr, hist[2], '--o', label='Train acc.')\n",
    "ax.plot(x_arr, hist[3], '--c', \n",
    "        label='Validation acc.')\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_xlabel('Epoch', size=15)\n",
    "ax.set_ylabel('Accuracy', size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(mnist_test_dataset.data.unsqueeze(1) / 255.)\n",
    "is_correct = (\n",
    "    torch.argmax(pred, dim=1) == mnist_test_dataset.targets\n",
    ").float()\n",
    "print(f'Test accuracy: {is_correct.mean():4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convertir Jupyter Notebook a Fichero Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python .convert_notebook_to_script.py --input ch14_notebook.ipynb --output ch14_notebook.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
