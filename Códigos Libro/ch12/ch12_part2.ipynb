{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with PyTorch and Scikit-Learn  \n",
    "# -- Code Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package version checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add folder to path in order to load from the check_packages.py script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * import sys\n",
    "# Import the sys module, which is a Python standard library module.\n",
    "# This module provides access to variables and functions that interact strongly with the\n",
    "# Python interpreter, such as manipulating module search path and input/output\n",
    "# standard, among others.\n",
    "# * sys.path\n",
    "# It is a list containing the paths in which the Python interpreter looks for modules when\n",
    "# you use import. When you try to import a module, Python searches the paths specified in this\n",
    "# list.\n",
    "# * sys.path.insert(0, '..')\n",
    "# Insert the path '..' (representing the parent directory) at the beginning of the sys.path list.\n",
    "# Adding it in position 0 ensures that when Python looks for modules to import,\n",
    "# first check in the parent directory before continuing with the default paths.\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check recommended package versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * from python_environment_check import check_packages\n",
    "# Import the check_packages function from the python_environment_check module. \n",
    "# This module, from its name, appears to be designed to verify that the Python environment \n",
    "# have the correct versions of certain packages installed.\n",
    "# * d = {...}\n",
    "# Defines a dictionary d that contains the names of several packages as keys \n",
    "# (e.g. numpy, scipy, matplotlib, etc.) and as values ​​the minimum versions \n",
    "# required from those packages.\n",
    "# * check_packages(d)\n",
    "# The check_packages function takes as input the dictionary d and probably performs a \n",
    "# check on current Python environment to ensure installed versions \n",
    "# of these packages are at least those specified in the dictionary. If any of the packages \n",
    "# is not installed or has the wrong version, the function may throw an error or \n",
    "# suggest installing/updating the packages.\n",
    "\n",
    "from python_environment_check import check_packages\n",
    "d = {\n",
    "    'numpy': '1.21.2',\n",
    "    'scipy': '1.7.0',\n",
    "    'sklearn': '1.0.0',\n",
    "    'matplotlib': '3.4.3',\n",
    "    'torch': '1.9.0',\n",
    "}\n",
    "check_packages(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 12: Parallelizing Neural Network Training with PyTorch  (Part 2/2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Building an NN model in PyTorch](#Building-an-NN-model-in-PyTorch)\n",
    "  - [The PyTorch neural network module (torch.nn)](#The-PyTorch-neural-network-module-(torch.nn))\n",
    "  - [Building a linear regression model](#Building-a-linear-regression-model)\n",
    "  - [Model training via the torch.nn and torch.optim modules](#Model-training-via-the-torch.nn-and-torch.optim-modules)\n",
    "  - [Building a multilayer perceptron for classifying flowers in the Iris dataset](#Building-a-multilayer-perceptron-for-classifying-flowers-in-the-Iris-dataset)\n",
    "  - [Evaluating the trained model on the test dataset](#Evaluating-the-trained-model-on-the-test-dataset)\n",
    "  - [Saving and reloading the trained model](#Saving-and-reloading-the-trained-model)\n",
    "- [Choosing activation functions for multilayer neural\n",
    "networks](#Choosing-activation-functions-for-multilayer-neural-networks)\n",
    "  - [Logistic function recap](#Logistic-function-recap)\n",
    "  - [Estimating class probabilities in multiclass classification via the softmax function](#Estimating-class-probabilities-in-multiclass-classification-via-the-softmax-function)\n",
    "  - [Broadening the output spectrum using a hyperbolic tangent](#Broadening-the-output-spectrum-using-a-hyperbolic-tangent)\n",
    "  - [Rectified linear unit activation](#Rectified-linear-unit-activation)\n",
    "- [Summary](#Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the optional watermark extension is a small IPython notebook plugin that I developed to make the code reproducible. You can just skip the following line(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * from IPython.display\n",
    "# Import from the display submodule of the IPython package. This module is designed to display \n",
    "# and render different types of data within interactive environments, such as Jupyter Notebooks.\n",
    "# * import Image\n",
    "# Import the Image class from the display module. The Image class is used to display \n",
    "# images in the interactive environment (for example, in a Jupyter Notebook cell).\n",
    "# * %matplotlib inline\n",
    "# This is a magic command specific to IPython/Jupyter Notebook.\n",
    "# Enables display of matplotlib plots directly within cells of the \n",
    "# notebook. Graphics are rendered \"inline\" (within the same notebook) without the need \n",
    "# to open pop-up windows.\n",
    "\n",
    "from IPython.display import Image as IPythonImage\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a neural network model in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The PyTorch neural network module (torch.nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.arange(10, dtype='float32').reshape((10, 1))\n",
    "y_train = np.array([1.0, 1.3, 3.1, 2.0, 5.0, 6.3, 6.6, \n",
    "                    7.4, 8.0, 9.0], dtype='float32')\n",
    "\n",
    "plt.plot(X_train, y_train, 'o', markersize=10)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "#plt.savefig('figures/12_07.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "X_train_norm = (X_train - np.mean(X_train)) / np.std(X_train)\n",
    "X_train_norm = torch.from_numpy(X_train_norm)\n",
    "\n",
    "# On some computers the explicit cast to .float() is\n",
    "# necessary\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "\n",
    "train_ds = TensorDataset(X_train_norm, y_train)\n",
    "\n",
    "batch_size = 1\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "weight = torch.randn(1)\n",
    "weight.requires_grad_()\n",
    "bias = torch.zeros(1, requires_grad=True)\n",
    " \n",
    "def loss_fn(input, target):\n",
    "    return (input-target).pow(2).mean()\n",
    "\n",
    "def model(xb):\n",
    "    return xb @ weight + bias\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 200\n",
    "log_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for x_batch, y_batch in train_dl:\n",
    "        pred = model(x_batch)\n",
    "        loss = loss_fn(pred, y_batch)\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            weight -= weight.grad * learning_rate\n",
    "            bias -= bias.grad * learning_rate\n",
    "            weight.grad.zero_()\n",
    "            bias.grad.zero_()\n",
    " \n",
    "    if epoch % log_epochs==0:\n",
    "        print(f'Epoch {epoch}  Loss {loss.item():.4f}')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final Parameters:', weight.item(), bias.item())\n",
    " \n",
    "X_test = np.linspace(0, 9, num=100, dtype='float32').reshape(-1, 1)\n",
    "X_test_norm = (X_test - np.mean(X_train)) / np.std(X_train)\n",
    "X_test_norm = torch.from_numpy(X_test_norm)\n",
    "y_pred = model(X_test_norm).detach().numpy()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(13, 5))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "plt.plot(X_train_norm, y_train, 'o', markersize=10)\n",
    "plt.plot(X_test_norm, y_pred, '--', lw=3)\n",
    "plt.legend(['Training examples', 'Linear Reg.'], fontsize=15)\n",
    "ax.set_xlabel('x', size=15)\n",
    "ax.set_ylabel('y', size=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    " \n",
    "#plt.savefig('figures/12_08.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training via the torch.nn and torch.optim modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for x_batch, y_batch in train_dl:\n",
    "        # 1. Generate predictions\n",
    "        pred = model(x_batch)[:, 0] \n",
    "\n",
    "        # 2. Calculate loss\n",
    "        loss = loss_fn(pred, y_batch)\n",
    "\n",
    "        # 3. Compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # 4. Update parameters using gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # 5. Reset the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    if epoch % log_epochs==0:\n",
    "        print(f'Epoch {epoch}  Loss {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final Parameters:', model.weight.item(), model.bias.item())\n",
    " \n",
    "X_test = np.linspace(0, 9, num=100, dtype='float32').reshape(-1, 1)\n",
    "X_test_norm = (X_test - np.mean(X_train)) / np.std(X_train)\n",
    "X_test_norm = torch.from_numpy(X_test_norm)\n",
    "y_pred = model(X_test_norm).detach().numpy()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(13, 5))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "plt.plot(X_train_norm.detach().numpy(), y_train.detach().numpy(), 'o', markersize=10)\n",
    "plt.plot(X_test_norm.detach().numpy(), y_pred.detach().numpy(), '--', lw=3)\n",
    "plt.legend(['Training examples', 'Linear reg.'], fontsize=15)\n",
    "ax.set_xlabel('x', size=15)\n",
    "ax.set_ylabel('y', size=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    " \n",
    "#plt.savefig('ch12-linreg-2.pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a multilayer perceptron for classifying flowers in the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=1./3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "X_train_norm = (X_train - np.mean(X_train)) / np.std(X_train)\n",
    "X_train_norm = torch.from_numpy(X_train_norm).float()\n",
    "y_train = torch.from_numpy(y_train) \n",
    "\n",
    "train_ds = TensorDataset(X_train_norm, y_train)\n",
    "\n",
    "torch.manual_seed(1)\n",
    "batch_size = 2\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)  \n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = nn.Sigmoid()(x)\n",
    "        x = self.layer2(x)\n",
    "        x = nn.Softmax(dim=1)(x)\n",
    "        return x\n",
    "    \n",
    "input_size = X_train_norm.shape[1]\n",
    "hidden_size = 16\n",
    "output_size = 3\n",
    " \n",
    "model = Model(input_size, hidden_size, output_size)\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    " \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "loss_hist = [0] * num_epochs\n",
    "accuracy_hist = [0] * num_epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for x_batch, y_batch in train_dl:\n",
    "        pred = model(x_batch)\n",
    "        loss = loss_fn(pred, y_batch.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        loss_hist[epoch] += loss.item()*y_batch.size(0)\n",
    "        is_correct = (torch.argmax(pred, dim=1) == y_batch).float()\n",
    "        accuracy_hist[epoch] += is_correct.sum()\n",
    "        \n",
    "    loss_hist[epoch] /= len(train_dl.dataset)\n",
    "    accuracy_hist[epoch] /= len(train_dl.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 5))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(loss_hist, lw=3)\n",
    "ax.set_title('Training loss', size=15)\n",
    "ax.set_xlabel('Epoch', size=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(accuracy_hist, lw=3)\n",
    "ax.set_title('Training accuracy', size=15)\n",
    "ax.set_xlabel('Epoch', size=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.savefig('figures/12_09.pdf')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the trained model on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_norm = (X_test - np.mean(X_train)) / np.std(X_train)\n",
    "X_test_norm = torch.from_numpy(X_test_norm).float()\n",
    "y_test = torch.from_numpy(y_test) \n",
    "pred_test = model(X_test_norm)\n",
    "\n",
    "correct = (torch.argmax(pred_test, dim=1) == y_test).float()\n",
    "accuracy = correct.mean()\n",
    " \n",
    "print(f'Test Acc.: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and reloading the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'iris_classifier.pt'\n",
    "torch.save(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = torch.load(path)\n",
    "model_new.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model_new(X_test_norm)\n",
    "\n",
    "correct = (torch.argmax(pred_test, dim=1) == y_test).float()\n",
    "accuracy = correct.mean()\n",
    " \n",
    "print(f'Test Acc.: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'iris_classifier_state.pt'\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = Model(input_size, hidden_size, output_size)\n",
    "model_new.load_state_dict(torch.load(path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing activation functions for multilayer neural networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic function recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([1, 1.4, 2.5]) ## first value must be 1\n",
    "w = np.array([0.4, 0.3, 0.5])\n",
    "\n",
    "def net_input(X, w):\n",
    "    return np.dot(X, w)\n",
    "\n",
    "def logistic(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def logistic_activation(X, w):\n",
    "    z = net_input(X, w)\n",
    "    return logistic(z)\n",
    "\n",
    "print(f'P(y=1|x) = {logistic_activation(X, w):.3f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W : array with shape = (n_output_units, n_hidden_units+1)\n",
    "# note that the first column are the bias units\n",
    "\n",
    "W = np.array([[1.1, 1.2, 0.8, 0.4],\n",
    "              [0.2, 0.4, 1.0, 0.2],\n",
    "              [0.6, 1.5, 1.2, 0.7]])\n",
    "\n",
    "# A : data array with shape = (n_hidden_units + 1, n_samples)\n",
    "# note that the first column of this array must be 1\n",
    "\n",
    "A = np.array([[1, 0.1, 0.4, 0.6]])\n",
    "Z = np.dot(W, A[0])\n",
    "y_probas = logistic(Z)\n",
    "print('Net Input: \\n', Z)\n",
    "\n",
    "print('Output Units:\\n', y_probas) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_class = np.argmax(Z, axis=0)\n",
    "print('Predicted class label:', y_class) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating class probabilities in multiclass classification via the softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    return np.exp(z) / np.sum(np.exp(z))\n",
    "\n",
    "y_probas = softmax(Z)\n",
    "print('Probabilities:\\n', y_probas)\n",
    "\n",
    "np.sum(y_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.softmax(torch.from_numpy(Z), dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadening the output spectrum using a hyperbolic tangent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def tanh(z):\n",
    "    e_p = np.exp(z)\n",
    "    e_m = np.exp(-z)\n",
    "    return (e_p - e_m) / (e_p + e_m)\n",
    "\n",
    "z = np.arange(-5, 5, 0.005)\n",
    "log_act = logistic(z)\n",
    "tanh_act = tanh(z)\n",
    "plt.ylim([-1.5, 1.5])\n",
    "plt.xlabel('Net input $z$')\n",
    "plt.ylabel('Activation $\\phi(z)$')\n",
    "plt.axhline(1, color='black', linestyle=':')\n",
    "plt.axhline(0.5, color='black', linestyle=':')\n",
    "plt.axhline(0, color='black', linestyle=':')\n",
    "plt.axhline(-0.5, color='black', linestyle=':')\n",
    "plt.axhline(-1, color='black', linestyle=':')\n",
    "plt.plot(z, tanh_act,\n",
    "    linewidth=3, linestyle='--',\n",
    "    label='Tanh')\n",
    "plt.plot(z, log_act,\n",
    "    linewidth=3,\n",
    "    label='Logistic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.savefig('figures/12_10.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.tanh(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tanh(torch.from_numpy(z))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "expit(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sigmoid(torch.from_numpy(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rectified linear unit activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.relu(torch.from_numpy(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * IPythonImage(...)\n",
    "# Use the IPythonImage class (probably imported from IPython.display, as in the previous example) \n",
    "# to display an image in an interactive environment such as Jupyter Notebook.\n",
    "# * filename='./figures/12_11.png'\n",
    "# Specifies the path of the image to display. In this case, the image is located in the\n",
    "# file './figures/12_11.png', which is a relative path to the current directory.\n",
    "# * width=500\n",
    "# Set the image width to 500 pixels. This resizes the image so that it occupies that \n",
    "# space width, while its height is adjusted proportionally (if you do not specify a \n",
    "# height).\n",
    "\n",
    "IPythonImage(filename='figures/12_11.png', width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Readers may ignore the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a command in the terminal from a Python environment (such as a Jupyter Notebook or a \n",
    "# script that allows system commands to convert a Jupyter notebook to a file Python script. \n",
    "# * !\n",
    "# This symbol is used in environments such as Jupyter Notebooks to execute system commands \n",
    "# operational directly from the notebook. In this case, the command is an execution of a \n",
    "# Python Script.\n",
    "# * python ../.convert_notebook_to_script.py\n",
    "# This command runs a Python script called convert_notebook_to_script.py. This file \n",
    "# is located in the previous directory (../ indicates that it is one level up in the system \n",
    "# files). The purpose of this script is to convert a Jupyter notebook (.ipynb) into a \n",
    "# Python script file (.py).\n",
    "# * --input ch12_part2.ipynb\n",
    "# This is an option or argument that tells the script what the input file is, in this \n",
    "# case, the notebook ch12_part2.ipynb.\n",
    "# * --output ch12_part2.py\n",
    "# This option tells the script to save the output (the converted file) with the name\n",
    "# ch12_part2.py, which is a Python script.\n",
    "\n",
    "! python ../.convert_notebook_to_script.py --input ch12_part2.ipynb --output ch12_part2.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
