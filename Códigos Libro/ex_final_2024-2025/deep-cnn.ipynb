{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional Neural Networks Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importación de bibliotecas para análisis y escalado de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se configuran las transformaciones necesarias para convertir las imágenes en tensores.\n",
    "\n",
    "Después, se carga el dataset FashionMNIST con imágenes de entrenamiento y validación, se divide el dataset original en conjuntos de entrenamiento y validación.\n",
    "\n",
    "Y por último, se carga el dataset de prueba sin volver a descargar las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:04<00:00, 5.88MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/raw/train-images-idx3-ubyte.gz to ./FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 819kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.42M/4.42M [00:01<00:00, 4.16MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 10.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "image_path = './'\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "mnist_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root=image_path, train=True,\n",
    "    transform=transform, download=True\n",
    ")\n",
    "from torch.utils.data import Subset\n",
    "mnist_valid_dataset = Subset(mnist_dataset, \n",
    "                             torch.arange(10000))\n",
    "mnist_train_dataset = Subset(mnist_dataset, \n",
    "                             torch.arange(\n",
    "                                 10000, len(mnist_dataset)\n",
    "                            ))\n",
    "mnist_test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root=image_path, train=False,\n",
    "    transform=transform, download=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se configura el tamaño del batch a 64 y se establecen las semillas aleatorias, además de crear 2 loaders, uno para el dataset de entrenamiento y otro para el de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "torch.manual_seed(1)\n",
    "train_dl = DataLoader(mnist_train_dataset,\n",
    "                      batch_size,\n",
    "                      shuffle=True)\n",
    "valid_dl = DataLoader(mnist_valid_dataset,\n",
    "                      batch_size,\n",
    "                      shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construyendo una CNN en PyTorch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se construye el modelo de la CNN y una segunda capa convolucional y de activación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "model.add_module(\n",
    "    'conv1',\n",
    "    nn.Conv2d(\n",
    "        in_channels=1, out_channels=32,\n",
    "        kernel_size=5, padding=2\n",
    "    )\n",
    ")\n",
    "model.add_module('relu1', nn.ReLU())\n",
    "model.add_module('pool1', nn.MaxPool2d(kernel_size=2))\n",
    "model.add_module(\n",
    "    'conv2',\n",
    "    nn.Conv2d(\n",
    "        in_channels=32, out_channels=64,\n",
    "        kernel_size=5, padding=2\n",
    "    )\n",
    ")\n",
    "model.add_module('relu2', nn.ReLU())\n",
    "model.add_module('pool2', nn.MaxPool2d(kernel_size=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se verifican las dimensiones después de haber creado las capas convolucionales y de pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 7, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones((4, 1, 28, 28))\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, las dimensiones de entrada de 28x28 se han reducido a 7x7 debido a la aplicación secuencial de las capas de convolución, activación y pooling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hecho esto, se aplana el tensor para aquellas capas que se encuentren completamente conectadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3136])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.add_module('flatten', nn.Flatten())\n",
    "x = torch.ones((4, 1, 28, 28))\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, el tensor ha pasado de tener dimensiones 64x7x7 a 3136, por lo que ya está listo para ser procesado por aquellas capas que se encuentren totalmente conectadas al modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después, se añaden las capas conectadas (fully connected) y de regularización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_module('fc1', nn.Linear(3136, 1024))\n",
    "model.add_module('relu3', nn.ReLU())\n",
    "model.add_module('dropout', nn.Dropout(p=0.5))\n",
    "model.add_module('fc2', nn.Linear(1024, 10))\n",
    "model = model.cpu()\n",
    "# model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se configuran tanto la función de pérdida como el optimizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, num_epochs, train_dl, valid_dl):\n",
    "    loss_hist_train = [0] * num_epochs\n",
    "    accuracy_hist_train = [0] * num_epochs\n",
    "    loss_hist_valid = [0] * num_epochs\n",
    "    accuracy_hist_valid = [0] * num_epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for x_batch, y_batch in train_dl:\n",
    "            x_batch = x_batch.cpu()\n",
    "            y_batch = y_batch.cpu()\n",
    "            # x_batch = x_batch.cuda()\n",
    "            # y_batch = y_batch.cuda()\n",
    "            pred = model(x_batch)\n",
    "            loss = loss_fn(pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss_hist_train[epoch] += loss.item()*y_batch.size(0)\n",
    "            is_correct = (\n",
    "                torch.argmax(pred, dim=1) == y_batch\n",
    "            ).float()\n",
    "            accuracy_hist_train[epoch] += is_correct.sum()\n",
    "        loss_hist_train[epoch] /= len(train_dl.dataset)\n",
    "        accuracy_hist_train[epoch] /= len(train_dl.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in valid_dl:\n",
    "                x_batch = x_batch.cpu()\n",
    "                y_batch = y_batch.cpu()\n",
    "                # x_batch = x_batch.cuda()\n",
    "                # y_batch = y_batch.cuda()\n",
    "                pred = model(x_batch)\n",
    "                loss = loss_fn(pred, y_batch)\n",
    "                loss_hist_valid[epoch] += \\\n",
    "                    loss.item()*y_batch.size(0)\n",
    "                is_correct = (\n",
    "                    torch.argmax(pred, dim=1) == y_batch\n",
    "                ).float()\n",
    "                accuracy_hist_valid[epoch] += is_correct.sum()\n",
    "        loss_hist_valid[epoch] /= len(valid_dl.dataset)\n",
    "        accuracy_hist_valid[epoch] /= len(valid_dl.dataset)\n",
    "        \n",
    "        print(f'Epoch {epoch+1} accuracy: '\n",
    "              f'{accuracy_hist_train[epoch]:.4f} val_accuracy: '\n",
    "              f'{accuracy_hist_valid[epoch]:.4f}')\n",
    "    return loss_hist_train, loss_hist_valid, \\\n",
    "        accuracy_hist_train, accuracy_hist_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrenamiento de la CNN (1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(1)\n",
    "# num_epochs = 20\n",
    "# hist = train(model, num_epochs, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las métricas impresas durante el entrenamiento muestran cómo evolucionan la pérdida y la precisión tanto en los conjuntos de entrenamiento como de validación.\n",
    "\n",
    "Es importante identificar si hay problemas como sobreajuste, observando la brecha entre la precisión de entrenamiento y validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_arr = np.arange(len(hist[0])) + 1\n",
    "# fig = plt.figure(figsize=(12,4))\n",
    "# ax = fig.add_subplot(1, 2, 1)\n",
    "# ax.plot(x_arr, hist[0], '--o', label='Train loss')\n",
    "# ax.plot(x_arr, hist[1], '--<', label='Validation loss')\n",
    "# ax.legend(fontsize=15)\n",
    "# ax = fig.add_subplot(1, 2, 2)\n",
    "# ax.plot(x_arr, hist[2], '--o', label='Train acc.')\n",
    "# ax.plot(x_arr, hist[3], '--<', label='Validation acc.')\n",
    "# ax.legend(fontsize=15)\n",
    "# ax.set_xlabel('Epoch', size=15)\n",
    "# ax.set_ylabel('Accuracy', size=15)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = model(mnist_test_dataset.data.unsqueeze(1) / 255.)\n",
    "# is_correct = (\n",
    "#     torch.argmax(pred, dim=1) == mnist_test_dataset.targets\n",
    "# ).float()\n",
    "# print(f'Test accuracy: {is_correct.mean():4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, los gráficos de pérdida y precisión permiten evaluar visualmente el rendimiento del modelo.\n",
    "\n",
    "Una convergencia estable indica que el modelo ha aprendido patrones relevantes sin sobreajustarse a los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrenamiento de la CNN (2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(1)\n",
    "# num_epochs = 20\n",
    "# hist = train(model, num_epochs, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las métricas impresas durante el entrenamiento muestran cómo evolucionan la pérdida y la precisión tanto en los conjuntos de entrenamiento como de validación.\n",
    "\n",
    "Es importante identificar si hay problemas como sobreajuste, observando la brecha entre la precisión de entrenamiento y validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(range(1, num_epochs+1), hist[0], label='Train loss')\n",
    "# plt.plot(range(1, num_epochs+1), hist[1], label='Valid loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Train loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(range(1, num_epochs+1), hist[2].cpu().numpy(), label='Accuracy train')\n",
    "# plt.plot(range(1, num_epochs+1), hist[3].cpu().numpy(), label='Accuracy valid')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, los gráficos de pérdida y precisión permiten evaluar visualmente el rendimiento del modelo.\n",
    "\n",
    "Una convergencia estable indica que el modelo ha aprendido patrones relevantes sin sobreajustarse a los datos de entrenamiento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
