{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Machine Learning with PyTorch and Scikit-Learn  \n",
    "# -- Code Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package version checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add folder to path in order to load from the check_packages.py script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check recommended package versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_environment_check import check_packages\n",
    "\n",
    "\n",
    "d = {\n",
    "    'numpy': '1.21.2',\n",
    "    'matplotlib': '3.4.3',\n",
    "    'torch': '1.8',\n",
    "    'mlxtend': '0.19.0'\n",
    "}\n",
    "check_packages(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 13: Going Deeper -- the Mechanics of PyTorch (Part 1/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outline**\n",
    "\n",
    "- [The key features of PyTorch](#The-key-features-of-PyTorch)\n",
    "- [PyTorch's computation graphs](#PyTorchs-computation-graphs)\n",
    "  - [Understanding computation graphs](#Understanding-computation-graphs)\n",
    "  - [Creating a graph in PyTorch](#Creating-a-graph-in-PyTorch)\n",
    "- [PyTorch tensor objects for storing and updating model parameters](#PyTorch-tensor-objects-for-storing-and-updating-model-parameters)\n",
    "- [Computing gradients via automatic differentiation](#Computing-gradients-via-automatic-differentiation)\n",
    "  - [Computing the gradients of the loss with respect to trainable variables](#Computing-the-gradients-of-the-loss-with-respect-to-trainable-variables)\n",
    "  - [Understanding automatic differentiation](#Understanding-automatic-differentiation)\n",
    "  - [Adversarial examples](#Adversarial-examples)\n",
    "- [Simplifying implementations of common architectures via the torch.nn module](#Simplifying-implementations-of-common-architectures-via-the-torch.nn-module)\n",
    "  - [Implementing models based on nn.Sequential](#Implementing-models-based-on-nn-Sequential)\n",
    "  - [Choosing a loss function](#Choosing-a-loss-function)\n",
    "  - [Solving an XOR classification problem](#Solving-an-XOR-classification-problem)\n",
    "  - [Making model building more flexible with nn.Module](#Making-model-building-more-flexible-with-nn.Module)\n",
    "  - [Writing custom layers in PyTorch](#Writing-custom-layers-in-PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The key features of PyTorch\n",
    "\n",
    "## PyTorch's computation graphs\n",
    "\n",
    "### Understanding computation graphs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='figures/13_01.png', width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a graph in PyTorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def compute_z(a, b, c):\n",
    "    r1 = torch.sub(a, b)\n",
    "    r2 = torch.mul(r1, 2)\n",
    "    z = torch.add(r2, c)\n",
    "    return z\n",
    "\n",
    "print('Scalar Inputs:', compute_z(torch.tensor(1), torch.tensor(2), torch.tensor(3)))\n",
    "print('Rank 1 Inputs:', compute_z(torch.tensor([1]), torch.tensor([2]), torch.tensor([3])))\n",
    "print('Rank 2 Inputs:', compute_z(torch.tensor([[1]]), torch.tensor([[2]]), torch.tensor([[3]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Tensor objects for storing and updating model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(3.14, requires_grad=True)\n",
    "b = torch.tensor([1.0, 2.0, 3.0], requires_grad=True) \n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "print(w.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.requires_grad_()\n",
    "\n",
    "print(w.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "torch.manual_seed(1)\n",
    "w = torch.empty(2, 3)\n",
    "nn.init.xavier_normal_(w)\n",
    "print(w)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.w1 = torch.empty(2, 3, requires_grad=True)\n",
    "        nn.init.xavier_normal_(self.w1)\n",
    "        self.w2 = torch.empty(1, 2, requires_grad=True)\n",
    "        nn.init.xavier_normal_(self.w2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing gradients via automatic differentiation and GradientTape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the gradients of the loss with respect to trainable variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(1.0, requires_grad=True)\n",
    "b = torch.tensor(0.5, requires_grad=True) \n",
    "\n",
    "x = torch.tensor([1.4])\n",
    "y = torch.tensor([2.1])\n",
    "\n",
    "\n",
    "z = torch.add(torch.mul(w, x), b)\n",
    " \n",
    "loss = (y-z).pow(2).sum()\n",
    "loss.backward()\n",
    "\n",
    "print('dL/dw : ', w.grad)\n",
    "print('dL/db : ', b.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifying the computed gradient dL/dw\n",
    "print(2 * x * ((w * x + b) - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplifying implementations of common architectures via the torch.nn module\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing models based on nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 32),\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuring layers\n",
    "\n",
    " * Initializers `nn.init`: https://pytorch.org/docs/stable/nn.init.html \n",
    " * L1 Regularizers `nn.L1Loss`: https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html#torch.nn.L1Loss\n",
    " * L2 Regularizers `weight_decay`: https://pytorch.org/docs/stable/optim.html\n",
    " * Activations: https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.init.xavier_uniform_(model[0].weight)\n",
    " \n",
    "l1_weight = 0.01\n",
    "l1_penalty = l1_weight * model[2].weight.abs().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling a model\n",
    "\n",
    " * Optimizers `torch.optim`:  https://pytorch.org/docs/stable/optim.html#algorithms\n",
    " * Loss Functions `tf.keras.losses`: https://pytorch.org/docs/stable/nn.html#loss-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving an XOR classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "x = np.random.uniform(low=-1, high=1, size=(200, 2))\n",
    "y = np.ones(len(x))\n",
    "y[x[:, 0] * x[:, 1]<0] = 0\n",
    "\n",
    "n_train = 100\n",
    "x_train = torch.tensor(x[:n_train, :], dtype=torch.float32)\n",
    "y_train = torch.tensor(y[:n_train], dtype=torch.float32)\n",
    "x_valid = torch.tensor(x[n_train:, :], dtype=torch.float32)\n",
    "y_valid = torch.tensor(y[n_train:], dtype=torch.float32)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "plt.plot(x[y==0, 0], \n",
    "         x[y==0, 1], 'o', alpha=0.75, markersize=10)\n",
    "plt.plot(x[y==1, 0], \n",
    "         x[y==1, 1], '<', alpha=0.75, markersize=10)\n",
    "plt.xlabel(r'$x_1$', size=15)\n",
    "plt.ylabel(r'$x_2$', size=15)\n",
    "\n",
    "#plt.savefig('figures/13_02.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    " \n",
    "    \n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "batch_size = 2\n",
    "torch.manual_seed(1)\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "num_epochs = 200\n",
    "def train(model, num_epochs, train_dl, x_valid, y_valid):\n",
    "    loss_hist_train = [0] * num_epochs\n",
    "    accuracy_hist_train = [0] * num_epochs\n",
    "    loss_hist_valid = [0] * num_epochs\n",
    "    accuracy_hist_valid = [0] * num_epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        for x_batch, y_batch in train_dl:\n",
    "            pred = model(x_batch)[:, 0]\n",
    "            loss = loss_fn(pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss_hist_train[epoch] += loss.item()\n",
    "            is_correct = ((pred>=0.5).float() == y_batch).float()\n",
    "            accuracy_hist_train[epoch] += is_correct.mean()\n",
    "\n",
    "        loss_hist_train[epoch] /= n_train/batch_size\n",
    "        accuracy_hist_train[epoch] /= n_train/batch_size\n",
    "\n",
    "        pred = model(x_valid)[:, 0]\n",
    "        loss = loss_fn(pred, y_valid)\n",
    "        loss_hist_valid[epoch] = loss.item()\n",
    "        is_correct = ((pred>=0.5).float() == y_valid).float()\n",
    "        accuracy_hist_valid[epoch] += is_correct.mean()\n",
    "    return loss_hist_train, loss_hist_valid, accuracy_hist_train, accuracy_hist_valid\n",
    "\n",
    "history = train(model, num_epochs, train_dl, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 4))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "plt.plot(history[0], lw=4)\n",
    "plt.plot(history[1], lw=4)\n",
    "plt.legend(['Train loss', 'Validation loss'], fontsize=15)\n",
    "ax.set_xlabel('Epochs', size=15)\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "plt.plot(history[2], lw=4)\n",
    "plt.plot(history[3], lw=4)\n",
    "plt.legend(['Train acc.', 'Validation acc.'], fontsize=15)\n",
    "ax.set_xlabel('Epochs', size=15)\n",
    "\n",
    "#plt.savefig('figures/13_03.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 4),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(4, 4),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(4, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    " \n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.015)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train(model, num_epochs, train_dl, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 4))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "plt.plot(history[0], lw=4)\n",
    "plt.plot(history[1], lw=4)\n",
    "plt.legend(['Train loss', 'Validation loss'], fontsize=15)\n",
    "ax.set_xlabel('Epochs', size=15)\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "plt.plot(history[2], lw=4)\n",
    "plt.plot(history[3], lw=4)\n",
    "plt.legend(['Train acc.', 'Validation acc.'], fontsize=15)\n",
    "ax.set_xlabel('Epochs', size=15)\n",
    "\n",
    "#plt.savefig('figures/13_04.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making model building more flexible with nn.Module\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        l1 = nn.Linear(2, 4)\n",
    "        a1 = nn.ReLU()\n",
    "        l2 = nn.Linear(4, 4)\n",
    "        a2 = nn.ReLU()\n",
    "        l3 = nn.Linear(4, 1)\n",
    "        a3 = nn.Sigmoid()\n",
    "        l = [l1, a1, l2, a2, l3, a3]\n",
    "        self.module_list = nn.ModuleList(l)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for f in self.module_list:\n",
    "            x = f(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        pred = self.forward(x)[:, 0]\n",
    "        return (pred>=0.5).float()\n",
    "            \n",
    "model = MyModule()\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.015)\n",
    "    \n",
    "# torch.manual_seed(1)\n",
    "history = train(model, num_epochs, train_dl, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "plt.plot(history[0], lw=4)\n",
    "plt.plot(history[1], lw=4)\n",
    "plt.legend(['Train loss', 'Validation loss'], fontsize=15)\n",
    "ax.set_xlabel('Epochs', size=15)\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "plt.plot(history[2], lw=4)\n",
    "plt.plot(history[3], lw=4)\n",
    "plt.legend(['Train acc.', 'Validation acc.'], fontsize=15)\n",
    "ax.set_xlabel('Epochs', size=15)\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 3)\n",
    "plot_decision_regions(X=x_valid.numpy(), \n",
    "                      y=y_valid.numpy().astype(np.int64),\n",
    "                      clf=model)\n",
    "ax.set_xlabel(r'$x_1$', size=15)\n",
    "ax.xaxis.set_label_coords(1, -0.025)\n",
    "ax.set_ylabel(r'$x_2$', size=15)\n",
    "ax.yaxis.set_label_coords(-0.025, 1)\n",
    "\n",
    "#plt.savefig('figures/13_05.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing custom layers in PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size, noise_stddev=0.1):\n",
    "        super().__init__()\n",
    "        w = torch.Tensor(input_size, output_size)\n",
    "        self.w = nn.Parameter(w)  # nn.Parameter is a Tensor that's a module parameter.\n",
    "        nn.init.xavier_uniform_(self.w)\n",
    "        b = torch.Tensor(output_size).fill_(0)\n",
    "        self.b = nn.Parameter(b)\n",
    "        self.noise_stddev = noise_stddev\n",
    "\n",
    "    def forward(self, x, training=False):\n",
    "        if training:\n",
    "            noise = torch.normal(0.0, self.noise_stddev, x.shape)\n",
    "            x_new = torch.add(x, noise)\n",
    "        else:\n",
    "            x_new = x\n",
    "        return torch.add(torch.mm(x_new, self.w), self.b)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing:\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "noisy_layer = NoisyLinear(4, 2)\n",
    " \n",
    "x = torch.zeros((1, 4))\n",
    "print(noisy_layer(x, training=True))\n",
    "\n",
    "print(noisy_layer(x, training=True))\n",
    " \n",
    "print(noisy_layer(x, training=False))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNoisyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = NoisyLinear(2, 4, 0.07)\n",
    "        self.a1 = nn.ReLU()\n",
    "        self.l2 = nn.Linear(4, 4)\n",
    "        self.a2 = nn.ReLU()\n",
    "        self.l3 = nn.Linear(4, 1)\n",
    "        self.a3 = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, training=False):\n",
    "        x = self.l1(x, training)\n",
    "        x = self.a1(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.a2(x)\n",
    "        x = self.l3(x)\n",
    "        x = self.a3(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        pred = self.forward(x)[:, 0]\n",
    "        return (pred>=0.5).float()\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model = MyNoisyModule()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.015)\n",
    "    \n",
    "torch.manual_seed(1)\n",
    "\n",
    "loss_hist_train = [0] * num_epochs\n",
    "accuracy_hist_train = [0] * num_epochs\n",
    "loss_hist_valid = [0] * num_epochs\n",
    "accuracy_hist_valid = [0] * num_epochs\n",
    "for epoch in range(num_epochs):\n",
    "    for x_batch, y_batch in train_dl:\n",
    "        pred = model(x_batch, True)[:, 0]\n",
    "        loss = loss_fn(pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        loss_hist_train[epoch] += loss.item()\n",
    "        is_correct = ((pred>=0.5).float() == y_batch).float()\n",
    "        accuracy_hist_train[epoch] += is_correct.mean()\n",
    "\n",
    "    loss_hist_train[epoch] /= n_train/batch_size\n",
    "    accuracy_hist_train[epoch] /= n_train/batch_size\n",
    "\n",
    "    pred = model(x_valid)[:, 0]\n",
    "    loss = loss_fn(pred, y_valid)\n",
    "    loss_hist_valid[epoch] = loss.item()\n",
    "    is_correct = ((pred>=0.5).float() == y_valid).float()\n",
    "    accuracy_hist_valid[epoch] += is_correct.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "plt.plot(loss_hist_train, lw=4)\n",
    "plt.plot(loss_hist_valid, lw=4)\n",
    "plt.legend(['Train loss', 'Validation loss'], fontsize=15)\n",
    "ax.set_xlabel('Epochs', size=15)\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "plt.plot(accuracy_hist_train, lw=4)\n",
    "plt.plot(accuracy_hist_valid, lw=4)\n",
    "plt.legend(['Train acc.', 'Validation acc.'], fontsize=15)\n",
    "ax.set_xlabel('Epochs', size=15)\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 3)\n",
    "plot_decision_regions(X=x_valid.numpy(), \n",
    "                      y=y_valid.numpy().astype(np.int64),\n",
    "                      clf=model)\n",
    "ax.set_xlabel(r'$x_1$', size=15)\n",
    "ax.xaxis.set_label_coords(1, -0.025)\n",
    "ax.set_ylabel(r'$x_2$', size=15)\n",
    "ax.yaxis.set_label_coords(-0.025, 1)\n",
    "\n",
    "#plt.savefig('figures/13_06.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Readers may ignore the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ../.convert_notebook_to_script.py --input ch13_part1.ipynb --output ch13_part1.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
